# 1. Dataset preparation using Python

## Overview
This task implements a dataset preparation pipeline for generating segmentation masks from the COCO dataset.

## Code Decisions and Edge Case Handling
- **Dataset Class:**  
  A custom PyTorch `Dataset` class (`COCOSegmentationDataset`) was implemented to load images and annotations from COCO and generate masks.
  
- **Mask Generation:**  
  - **Binary Masks:** Uses `np.maximum` to merge overlapping masks.
  - **Multi-class Masks:** Multiplies the binary mask with category indices to assign different values.
  
- **Error and Edge Case Handling:**  
  Overlapping masks are merged using `np.maximum` and annotations without a corresponding category are set to background (pixel value 0). Edge cases, such as potential annotation errors, are delegated to the COCO API but can be extended with additional exception handling.

### Example Image and Mask

Below are example outputs generated by the visualization script:

- **Image and Mask Example:**  
  ![Example Image](https://github.com/pavankz/Image-Segmentation-Assignmnet/blob/main/COCO/visualize_images/img_0010.png)

  
#  2. U-Net for Binary Image Segmentation
## Overview

A U-Net model was implemented using PyTorch to perform binary segmentation on images. The dataset used follows COCO-style formatting and includes custom binary masks for each object.

## Architecture
The U-Net architecture used includes:

- **Encoder**: Four downsampling blocks with double convolutions
- **Bottleneck**: A central block with 1024 channels
- **Decoder**: Four upsampling blocks using `ConvTranspose2D` and skip connections
- **Output**: 1-channel output with Sigmoid activation for binary mask prediction

---
Visualization of architecture with sample input : batch_size=1, 3 color channels, image size 224x224
<img src="https://github.com/pavankz/Image-Segmentation-Assignmnet/blob/main/COCO/unet_architecture.png" style="transform: rotate(90deg); width:400px;" />
##  Training Configuration

| Component       | Details              |
|----------------|----------------------|
| Optimizer       | Adam                |
| Learning Rate   | 1e-4                |
| Loss Function   | Binary Cross Entropy (BCE) |
| Epochs          | 10                  |
| Batch Size      | (depends on loader) |
| Device          | CUDA 12.4   |
| Logging         | [Weights & Biases Dashboard](https://wandb.ai/pavankumaar-amgoth-indian-institute-of-science/unet-segmentation/runs/6fq0lu4l?nw=nwuserpavankumaaramgoth) |

---
##  Modeling Decisions

- **Simple U-Net from scratch**: Fast to implement and easy to debug.
- **Binary cross-entropy**: Best suited for binary segmentation.
- **Manual sigmoid output**: Makes training interpretable and helps with post-processing thresholding.
- **No data augmentation**: Initial training used raw images to benchmark baseline performance.

---
##  Challenges & Fixes

| Issue | Resolution |
|-------|------------|
| Blurry masks | Switched from raw `torch.sigmoid` to explicitly using `nn.Sigmoid()` |
| Slow convergence | Added `torch.device()` GPU support |
| Overfitting | Tracking validation loss with early stopping (to be added) |

---

Training Metrics

![loss_curves](https://github.com/pavankz/Image-Segmentation-Assignmnet/blob/main/COCO/wandb_loss_curve.png)

Loss curves show steady convergence.

---
##  System Specs

| Resource | Specs |
|----------|-------|
| GPU      | NVIDIA A100 80GB PCIe |
| RAM      | 80 GB |
| Platform | Ubuntu 22.04 LTS |
| Tools    | PyTorch, WandB | 


## Reproduction Instructions on Linux
**Clone the repository:**
   ```bash
   git clone https://github.com/pavankz/Image-Segmentation-Assignment.git
   cd Image-Segmentation-Assignment
```

1. **Requirements**:
    Ensure the following libraries are installed:
    - TensorFlow /PyTorch
    - NumPy, Pandas
    - Matplotlib
    - WandB
    - tqtm

2. **Image Segemetation and Training**:
    - Open the `image_segmentation_model_training.ipynb` notebook.
    - Ensure the dataset path is correctly set up.
    - Run the notebook .

  ```python
import torch
model = load_model('unet_model.pth')
 ```
